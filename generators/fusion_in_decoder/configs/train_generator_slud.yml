# experiment
name: "fusion-in-decoder"
seed: 2022
total_step: 30000
eval_step: 20

# dataset
train_data: "/code/AIO3_FiD_baseline/datasets/fusion_in_decoder/DprRetrieved/train.jsonl"
eval_data: "/code/AIO3_FiD_baseline/datasets/fusion_in_decoder/DprRetrieved/dev.jsonl"
checkpoint_dir: "model"

# model 
model_name_or_path: "sonoisa/t5-base-japanese"
use_checkpoint: True
n_context: 2
text_max_length: 20

# training (optimizer & scheduler)
optim: adamw
scheduler: linear
lr: 5e-5
clip: 1.0
warmup_step: 1000
total_steps: 30000
weight_decay: 0.01
per_gpu_batch_size: 1

is_distributed: False
